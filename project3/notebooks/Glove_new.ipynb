{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cd9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchtext\n",
    "\n",
    "# Load pre-trained GloVe embeddings\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801a94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"C:\\\\Users\\\\agnes\\\\Documents\\\\apziva_ai_residency\\\\project3\\\\data\\\\potential-talents.csv\")\n",
    "words=data.job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2536a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Define a function to convert a string to an embedding vector\n",
    "def string_to_embedding(string):\n",
    "  # Tokenize the string\n",
    "  tokens = string.split()\n",
    "  # Get the index of each word in the vocabulary\n",
    "  indices = [glove.stoi[token] for token in tokens if token in glove.stoi]\n",
    "  # Get the embedding vector for each word\n",
    "  vectors = glove.vectors[indices]\n",
    "  #print(type(vectors))\n",
    "  # Compute the average of the vectors\n",
    "  embedding = torch.mean(vectors)\n",
    "  return embedding\n",
    "\n",
    "\n",
    "#data[\"embedding\"] = data[\"job_title\"].apply(string_to_embedding)\n",
    "#print(string_to_embedding(data[\"job_title\"][1]))\n",
    "\n",
    "\n",
    "job_tensors=[\"\"]*len(data[\"job_title\"])\n",
    "for i in range(len(data[\"job_title\"])):\n",
    "    job_tensors[i]=string_to_embedding(data[\"job_title\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a24dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0335), tensor(-0.0177), tensor(nan), tensor(0.0167), tensor(0.0167), tensor(nan), tensor(0.0229), tensor(nan), tensor(0.0229), tensor(0.0291), tensor(0.0167), tensor(0.0318), tensor(0.0167), tensor(0.0335), tensor(0.0335), tensor(-0.0177), tensor(nan), tensor(0.0167), tensor(0.0335), tensor(-0.0177), tensor(nan), tensor(0.0167), tensor(0.0167), tensor(nan), tensor(0.0229), tensor(nan), tensor(0.0128), tensor(nan), tensor(0.0128), tensor(nan), tensor(0.0335), tensor(-0.0177), tensor(nan), tensor(0.0167), tensor(0.0167), tensor(nan), tensor(0.0229), tensor(nan), tensor(0.0229), tensor(0.0291), tensor(0.0167), tensor(0.0318), tensor(0.0167), tensor(0.0335), tensor(-0.0177), tensor(nan), tensor(0.0167), tensor(0.0167), tensor(nan), tensor(0.0229), tensor(nan), tensor(0.0229), tensor(0.0291), tensor(0.0167), tensor(0.0318), tensor(0.0167), tensor(0.0335), tensor(nan), tensor(0.0167), tensor(nan), tensor(nan), tensor(0.0291), tensor(0.0167), tensor(0.0318), tensor(0.0167), tensor(0.0518), tensor(0.0291), tensor(0.0167), tensor(-0.0349), tensor(-0.0388), tensor(0.0167), tensor(0.0291), tensor(-0.0107), tensor(nan), tensor(0.0282), tensor(0.0532), tensor(-0.0147), tensor(0.0167), tensor(nan), tensor(nan), tensor(0.0167), tensor(0.0407), tensor(0.0167), tensor(-0.0269), tensor(0.0167), tensor(0.0523), tensor(-0.0355), tensor(nan), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0575), tensor(0.0196), tensor(0.0563), tensor(0.0167), tensor(0.0456), tensor(nan), tensor(nan), tensor(nan), tensor(0.0399), tensor(0.0167), tensor(0.0229), tensor(0.0349), tensor(0.0167)]\n"
     ]
    }
   ],
   "source": [
    "print(job_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9297d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "## getting cosine similarity \n",
    "set_of_strings = [\"Aspiring human resources\", \"seeking human resources\"] \n",
    "str_tensors=[\"\"]* len(set_of_strings)\n",
    "for i in range(len(set_of_strings)):\n",
    "    str_tensors[i]=string_to_embedding(set_of_strings[i])\n",
    "print(type(str_tensors[0]))\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "output = cos(str_tensors[0], str_tensors[1])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b39fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "for i in range(len(job_tensors)):  \n",
    "    #print(\"+++++\")\n",
    "    #print(job_tensors[i])\n",
    "    #print(str_tensors[0])\n",
    "    #print('-------')\n",
    "    print(cos(str_tensors[0], job_tensors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to calculate cosine similarity -> dimensions are different\n",
    "data[\"embedding\"] = data[\"job_title\"].apply(string_to_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5782a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.0335)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(-0.0177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.0167)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.0167)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit        embedding  \n",
       "0                       Houston, Texas         85  NaN   tensor(0.0335)  \n",
       "1                               Kanada      500+   NaN  tensor(-0.0177)  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN      tensor(nan)  \n",
       "3                        Denton, Texas      500+   NaN   tensor(0.0167)  \n",
       "4                       İzmir, Türkiye      500+   NaN   tensor(0.0167)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f8db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_strings = [\"Aspiring human resources\", \"seeking human resources\"] \n",
    "str_tensors=[\"\"]* len(set_of_strings)\n",
    "for i in range(len(set_of_strings)):\n",
    "    str_tensors[i]=string_to_embedding(set_of_strings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5192368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'Y' parameter of cosine_similarity must be an array-like, a sparse matrix or None. Got '0       tensor(0.0335)\\n1      tensor(-0.0177)\\n2          tensor(nan)\\n3       tensor(0.0167)\\n4       tensor(0.0167)\\n5          tensor(nan)\\n6       tensor(0.0229)\\n7          tensor(nan)\\n8       tensor(0.0229)\\n9       tensor(0.0291)\\n10      tensor(0.0167)\\n11      tensor(0.0318)\\n12      tensor(0.0167)\\n13      tensor(0.0335)\\n14      tensor(0.0335)\\n15     tensor(-0.0177)\\n16         tensor(nan)\\n17      tensor(0.0167)\\n18      tensor(0.0335)\\n19     tensor(-0.0177)\\n20         tensor(nan)\\n21      tensor(0.0167)\\n22      tensor(0.0167)\\n23         tensor(nan)\\n24      tensor(0.0229)\\n25         tensor(nan)\\n26      tensor(0.0128)\\n27         tensor(nan)\\n28      tensor(0.0128)\\n29         tensor(nan)\\n30      tensor(0.0335)\\n31     tensor(-0.0177)\\n32         tensor(nan)\\n33      tensor(0.0167)\\n34      tensor(0.0167)\\n35         tensor(nan)\\n36      tensor(0.0229)\\n37         tensor(nan)\\n38      tensor(0.0229)\\n39      tensor(0.0291)\\n40      tensor(0.0167)\\n41      tensor(0.0318)\\n42      tensor(0.0167)\\n43      tensor(0.0335)\\n44     tensor(-0.0177)\\n45         tensor(nan)\\n46      tensor(0.0167)\\n47      tensor(0.0167)\\n48         tensor(nan)\\n49      tensor(0.0229)\\n50         tensor(nan)\\n51      tensor(0.0229)\\n52      tensor(0.0291)\\n53      tensor(0.0167)\\n54      tensor(0.0318)\\n55      tensor(0.0167)\\n56      tensor(0.0335)\\n57         tensor(nan)\\n58      tensor(0.0167)\\n59         tensor(nan)\\n60         tensor(nan)\\n61      tensor(0.0291)\\n62      tensor(0.0167)\\n63      tensor(0.0318)\\n64      tensor(0.0167)\\n65      tensor(0.0518)\\n66      tensor(0.0291)\\n67      tensor(0.0167)\\n68     tensor(-0.0349)\\n69     tensor(-0.0388)\\n70      tensor(0.0167)\\n71      tensor(0.0291)\\n72     tensor(-0.0107)\\n73         tensor(nan)\\n74      tensor(0.0282)\\n75      tensor(0.0532)\\n76     tensor(-0.0147)\\n77      tensor(0.0167)\\n78         tensor(nan)\\n79         tensor(nan)\\n80      tensor(0.0167)\\n81      tensor(0.0407)\\n82      tensor(0.0167)\\n83     tensor(-0.0269)\\n84      tensor(0.0167)\\n85      tensor(0.0523)\\n86     tensor(-0.0355)\\n87         tensor(nan)\\n88      tensor(0.0167)\\n89      tensor(0.0167)\\n90      tensor(0.0167)\\n91      tensor(0.0575)\\n92      tensor(0.0196)\\n93      tensor(0.0563)\\n94      tensor(0.0167)\\n95      tensor(0.0456)\\n96         tensor(nan)\\n97         tensor(nan)\\n98         tensor(nan)\\n99      tensor(0.0399)\\n100     tensor(0.0167)\\n101     tensor(0.0229)\\n102     tensor(0.0349)\\n103     tensor(0.0167)' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1568/1524548291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(type(data[\"embedding\"]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcosine_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_ignore\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             validate_parameter_constraints(\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mparameter_constraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaller_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 )\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise InvalidParameterError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'Y' parameter of cosine_similarity must be an array-like, a sparse matrix or None. Got '0       tensor(0.0335)\\n1      tensor(-0.0177)\\n2          tensor(nan)\\n3       tensor(0.0167)\\n4       tensor(0.0167)\\n5          tensor(nan)\\n6       tensor(0.0229)\\n7          tensor(nan)\\n8       tensor(0.0229)\\n9       tensor(0.0291)\\n10      tensor(0.0167)\\n11      tensor(0.0318)\\n12      tensor(0.0167)\\n13      tensor(0.0335)\\n14      tensor(0.0335)\\n15     tensor(-0.0177)\\n16         tensor(nan)\\n17      tensor(0.0167)\\n18      tensor(0.0335)\\n19     tensor(-0.0177)\\n20         tensor(nan)\\n21      tensor(0.0167)\\n22      tensor(0.0167)\\n23         tensor(nan)\\n24      tensor(0.0229)\\n25         tensor(nan)\\n26      tensor(0.0128)\\n27         tensor(nan)\\n28      tensor(0.0128)\\n29         tensor(nan)\\n30      tensor(0.0335)\\n31     tensor(-0.0177)\\n32         tensor(nan)\\n33      tensor(0.0167)\\n34      tensor(0.0167)\\n35         tensor(nan)\\n36      tensor(0.0229)\\n37         tensor(nan)\\n38      tensor(0.0229)\\n39      tensor(0.0291)\\n40      tensor(0.0167)\\n41      tensor(0.0318)\\n42      tensor(0.0167)\\n43      tensor(0.0335)\\n44     tensor(-0.0177)\\n45         tensor(nan)\\n46      tensor(0.0167)\\n47      tensor(0.0167)\\n48         tensor(nan)\\n49      tensor(0.0229)\\n50         tensor(nan)\\n51      tensor(0.0229)\\n52      tensor(0.0291)\\n53      tensor(0.0167)\\n54      tensor(0.0318)\\n55      tensor(0.0167)\\n56      tensor(0.0335)\\n57         tensor(nan)\\n58      tensor(0.0167)\\n59         tensor(nan)\\n60         tensor(nan)\\n61      tensor(0.0291)\\n62      tensor(0.0167)\\n63      tensor(0.0318)\\n64      tensor(0.0167)\\n65      tensor(0.0518)\\n66      tensor(0.0291)\\n67      tensor(0.0167)\\n68     tensor(-0.0349)\\n69     tensor(-0.0388)\\n70      tensor(0.0167)\\n71      tensor(0.0291)\\n72     tensor(-0.0107)\\n73         tensor(nan)\\n74      tensor(0.0282)\\n75      tensor(0.0532)\\n76     tensor(-0.0147)\\n77      tensor(0.0167)\\n78         tensor(nan)\\n79         tensor(nan)\\n80      tensor(0.0167)\\n81      tensor(0.0407)\\n82      tensor(0.0167)\\n83     tensor(-0.0269)\\n84      tensor(0.0167)\\n85      tensor(0.0523)\\n86     tensor(-0.0355)\\n87         tensor(nan)\\n88      tensor(0.0167)\\n89      tensor(0.0167)\\n90      tensor(0.0167)\\n91      tensor(0.0575)\\n92      tensor(0.0196)\\n93      tensor(0.0563)\\n94      tensor(0.0167)\\n95      tensor(0.0456)\\n96         tensor(nan)\\n97         tensor(nan)\\n98         tensor(nan)\\n99      tensor(0.0399)\\n100     tensor(0.0167)\\n101     tensor(0.0229)\\n102     tensor(0.0349)\\n103     tensor(0.0167)' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#print(str_tensors)\n",
    "data_embedding=data[\"embedding\"].to_string()\n",
    "print(type(str_tensors))\n",
    "#print(type(data[\"embedding\"]))\n",
    "cosine_sim = cosine_similarity(str_tensors[0],data_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbce55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
